
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>4. Principled Amortized Bayesian Workflow for Cognitive Modeling &#8212; BayesFlow: Amortized Bayesian Inference</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_examples/LCA_Model_Posterior_Estimation';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://www.bayesflow.org/_examples/LCA_Model_Posterior_Estimation.html" />
    <link rel="icon" href="../_static/bayesflow_hex.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5. Posterior Estimation for ODEs" href="Linear_ODE_system.html" />
    <link rel="prev" title="3. Detecting Model Misspecification in Amortized Posterior Inference" href="Model_Misspecification.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/bayesflow_hex.png" class="logo__image only-light" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
    <script>document.write(`<img src="../_static/bayesflow_hex.png" class="logo__image only-dark" alt="BayesFlow: Amortized Bayesian Inference - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../index.html">BayesFlow</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../examples.html">Examples</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Intro_Amortized_Posterior_Estimation.html">1. Quickstart: Amortized Posterior Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="TwoMoons_Bimodal_Posterior.html">2. Two Moons: Tackling Bimodal Posteriors</a></li>
<li class="toctree-l2"><a class="reference internal" href="Model_Misspecification.html">3. Detecting Model Misspecification in Amortized Posterior Inference</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">4. Principled Amortized Bayesian Workflow for Cognitive Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="Linear_ODE_system.html">5. Posterior Estimation for ODEs</a></li>
<li class="toctree-l2"><a class="reference internal" href="Covid19_Initial_Posterior_Estimation.html">6. Posterior Estimation for SIR-like Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="Model_Comparison_MPT.html">7. Model Comparison for Cognitive Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="Hierarchical_Model_Comparison_MPT.html">8. Hierarchical Model Comparison for Cognitive Models</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/bayesflow.html">Public API: bayesflow package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/bayesflow.benchmarks.html">bayesflow.benchmarks package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.bernoulli_glm.html">bayesflow.benchmarks.bernoulli_glm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.bernoulli_glm_raw.html">bayesflow.benchmarks.bernoulli_glm_raw module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.gaussian_linear.html">bayesflow.benchmarks.gaussian_linear module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.gaussian_linear_uniform.html">bayesflow.benchmarks.gaussian_linear_uniform module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.gaussian_mixture.html">bayesflow.benchmarks.gaussian_mixture module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.inverse_kinematics.html">bayesflow.benchmarks.inverse_kinematics module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.lotka_volterra.html">bayesflow.benchmarks.lotka_volterra module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.sir.html">bayesflow.benchmarks.sir module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.slcp.html">bayesflow.benchmarks.slcp module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.slcp_distractors.html">bayesflow.benchmarks.slcp_distractors module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.two_moons.html">bayesflow.benchmarks.two_moons module</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.amortizers.html">bayesflow.amortizers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.attention.html">bayesflow.attention module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.coupling_networks.html">bayesflow.coupling_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.diagnostics.html">bayesflow.diagnostics module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.inference_networks.html">bayesflow.inference_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.losses.html">bayesflow.losses module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.networks.html">bayesflow.networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.sensitivity.html">bayesflow.sensitivity module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.simulation.html">bayesflow.simulation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.summary_networks.html">bayesflow.summary_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.trainers.html">bayesflow.trainers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.configuration.html">bayesflow.configuration module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.default_settings.html">bayesflow.default_settings module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.computational_utilities.html">bayesflow.computational_utilities module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.helper_classes.html">bayesflow.helper_classes module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.helper_functions.html">bayesflow.helper_functions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.helper_networks.html">bayesflow.helper_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.exceptions.html">bayesflow.exceptions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.mcmc.html">bayesflow.mcmc module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.version.html">bayesflow.version module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.wrappers.html">bayesflow.wrappers module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/bayesflow.experimental.html">bayesflow.experimental package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.experimental.rectifiers.html">bayesflow.experimental.rectifiers module</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Full Installation Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to BayesFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About us</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/stefanradev93/BayesFlow" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/stefanradev93/BayesFlow/edit/master/_examples/LCA_Model_Posterior_Estimation.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/stefanradev93/BayesFlow/issues/new?title=Issue%20on%20page%20%2F_examples/LCA_Model_Posterior_Estimation.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/_examples/LCA_Model_Posterior_Estimation.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Principled Amortized Bayesian Workflow for Cognitive Modeling</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-contents">4.1. Table of Contents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">4.2. Introduction <a class="anchor" id="introduction"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-model-specification">4.3. Generative Model Specification <a class="anchor" id="generative_model_specification"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-simulator">4.3.1. Creating a Simulator <a class="anchor" id="creating_a_simulator"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-prior-distributions">4.3.2. Defining Prior Distributions <a class="anchor" id="defining_prior_distributions"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#context-variables-for-general-amortized-inference">4.3.3. Context Variables for General Amortized Inference <a class="anchor" id="context_variables_for"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulator">4.3.4. Simulator <a class="anchor" id="simulator"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-pushforward-check">4.4. Prior Pushforward Check <a class="anchor" id="prior_pushforward_check"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-neural-approximator">4.5. Defining the Neural Approximator <a class="anchor" id="defining_the_neural"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-network">4.5.1. Summary Network <a class="anchor" id="summary_network"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-network">4.5.2. Inference Network <a class="anchor" id="inference_network"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#amortized-posterior">4.5.3. Amortized Posterior <a class="anchor" id="amortized_posterior"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-configurator">4.6. Defining the Configurator <a class="anchor" id="defining_the_configurator"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-trainer">4.7. Defining the Trainer <a class="anchor" id="defining_the_trainer"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-phase">4.8. Training Phase <a class="anchor" id="training_phase"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#validation">4.9. Validation <a class="anchor" id="validation"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-based-calibration">4.9.1. Simulation-Based Calibration <a class="anchor" id="simulation_based_calibration"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-sensitivity">4.9.2. Model Sensitivity <a class="anchor" id="model_sensitivity"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-retrodictive-checks-in-silico">4.9.3. Posterior Retrodictive Checks in Silico <a class="anchor" id="posterior_retrodictive_checks"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-phase">4.10. Inference Phase <a class="anchor" id="inference_phase"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-experimentation">4.11. Further Experimentation <a class="anchor" id="further_experimentation"></a></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="principled-amortized-bayesian-workflow-for-cognitive-modeling">
<h1><span class="section-number">4. </span>Principled Amortized Bayesian Workflow for Cognitive Modeling<a class="headerlink" href="#principled-amortized-bayesian-workflow-for-cognitive-modeling" title="Link to this heading">#</a></h1>
<p>by Lukas Schumacher &amp; Stefan T. Radev</p>
<section id="table-of-contents">
<h2><span class="section-number">4.1. </span>Table of Contents<a class="headerlink" href="#table-of-contents" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="#introduction"><span class="xref myst">Introduction</span></a></p></li>
<li><p><a class="reference internal" href="#generative_model_specification"><span class="xref myst">Generative Model Specification</span></a></p>
<ul>
<li><p><a class="reference internal" href="#creating_a_simulator"><span class="xref myst">Creating a Simulator</span></a></p></li>
<li><p><a class="reference internal" href="#defining_prior_distributions"><span class="xref myst">Defining Prior Distributions</span></a></p></li>
<li><p><a class="reference internal" href="#context_variables_for"><span class="xref myst">Context Variables for General Amortized Inference</span></a></p></li>
<li><p><a class="reference internal" href="../api/bayesflow.benchmarks.bernoulli_glm.html#bayesflow.benchmarks.bernoulli_glm.simulator" title="bayesflow.benchmarks.bernoulli_glm.simulator"><span class="xref myst py py-func">Simulator</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#prior_pushforward_check"><span class="xref myst">Prior Pushforward Check</span></a></p></li>
<li><p><a class="reference internal" href="#defining_the_neural"><span class="xref myst">Defining the Neural Approximator</span></a></p>
<ul>
<li><p><a class="reference internal" href="#summary_network"><span class="xref myst">Summary Network</span></a></p></li>
<li><p><a class="reference internal" href="#inference_network"><span class="xref myst">Inference Network</span></a></p></li>
<li><p><a class="reference internal" href="#amortized_posterior"><span class="xref myst">Amortized Posterior</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#defining_the_configurator"><span class="xref myst">Defining the Configurator</span></a></p></li>
<li><p><a class="reference internal" href="#defining_the_trainer"><span class="xref myst">Defining the Trainer</span></a></p></li>
<li><p><a class="reference internal" href="#training_phase"><span class="xref myst">Training Phase</span></a></p></li>
<li><p><a class="reference internal" href="#validation"><span class="xref myst">Validation</span></a></p>
<ul>
<li><p><a class="reference internal" href="#simulation_based_calibration"><span class="xref myst">Simulation-Based Calibration</span></a></p></li>
<li><p><a class="reference internal" href="#model_sensitivity"><span class="xref myst">Model Sensitivity</span></a></p></li>
<li><p><a class="reference internal" href="#posterior_retrodictive_checks"><span class="xref myst">Posterior Retrodictive Checks in Silico</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#inference_phase"><span class="xref myst">Inference Phase</span></a></p></li>
<li><p><a class="reference internal" href="#further_experimentation"><span class="xref myst">Further Experimentation</span></a></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">import</span> <span class="nn">bayesflow</span> <span class="k">as</span> <span class="nn">bf</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Suppress scientific notation for floats</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">njit</span>
<span class="k">except</span> <span class="ne">ModuleNotFoundError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please run `!pip install numba` and restart the kernel for utilizing just-in-time compilation.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="introduction">
<h2><span class="section-number">4.2. </span>Introduction <a class="anchor" id="introduction"></a><a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>Psychological research often relies on mathematical models to explain and predict human behavior.
Such models aim to formalize cognitive processes by mapping latent psychological constructs to model parameters and specifying how these generate manifest data. In this tutorial, we go through the steps of a principled <a class="reference external" href="https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html">Bayesian workflow</a> that is imperative when developing and applying cognitive models.
This workflow includes the following steps:</p>
<ol class="arabic simple">
<li><p>Prior pushforward and prior predictive checks to assess whether the model is consistent with our domain expertise;</p></li>
<li><p>Computational faithfulness checks to ensure that our estimation method can accurately approximate the posterior distributions;</p></li>
<li><p>Model sensitivity to examine if our inferences provide sufficient information for answering our research question;</p></li>
<li><p>Posterior retrodictive checks to assess whether our model can capture the relevant structure of the true data-generating process;</p></li>
</ol>
<p>To demonstrate how such a workflow is performed in an amortized manner using <strong>BayesFlow</strong>, we will take a complex model from the evidence accumulaton model (EAM) family which is intractable for standard Bayesian methods.</p>
</section>
<section id="generative-model-specification">
<h2><span class="section-number">4.3. </span>Generative Model Specification <a class="anchor" id="generative_model_specification"></a><a class="headerlink" href="#generative-model-specification" title="Link to this heading">#</a></h2>
<p>Evidence accumulation models (EAM) are among the most commonly used cognitive models in psychological research. These decision models account for both choice and response time data by assuming that cognitive agents accumulate evidence for decision alternatives until an internal threshold is reached. This process is typically formalized as a random walk with drift. The standard EAM has four core parameters, each corresponding to a specific latent cognitive construct: i) the drift rate <span class="math notranslate nohighlight">\(v\)</span> represents perceptual processing speed; ii) the threshold <span class="math notranslate nohighlight">\(a\)</span> reflects decision caution; iii) the starting point <span class="math notranslate nohighlight">\(\beta\)</span> determines decisional biases, and iv) the non-decision time <span class="math notranslate nohighlight">\(\tau\)</span> accounts for decision-unrelated processes such as motor actions and perceptual encoding.</p>
<p>There are many model variations within the EAM class. Througout this tutorial, we will focus on the leaky competing accumulator (LCA) model proposed by <a class="reference external" href="https://psycnet.apa.org/record/2001-07628-003">Usher and McClelland (2001)</a>. The likelihood function of this model is not known in closed form. This makes it a perfect candidate for <tt>BayesFlow</tt>, as it can handle any model that can be implemented as a randomized data simulator.</p>
<p>The LCA assumes a competition between seperate accumulators <span class="math notranslate nohighlight">\(A_j\)</span>, each corresponding to a decision alternative <span class="math notranslate nohighlight">\(j\)</span>. The accumulator <span class="math notranslate nohighlight">\(A_j\)</span> that first hits its threshold wins and the corresponding decision will be made. Evidence accumulation for a certain decision alternative follows a Wiener process with two additional features:</p>
<ol class="arabic simple">
<li><p>Evidence leakage or decay <span class="math notranslate nohighlight">\(\lambda\)</span> that accounts for information loss over time within each accumulator</p></li>
<li><p>Lateral inhibition <span class="math notranslate nohighlight">\(\kappa\)</span>, which represents accumulator activation damping from the other accumulators.</p></li>
</ol>
<p>The activiation of a single accumulator <span class="math notranslate nohighlight">\(x_j\)</span> is thus updated as follow:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathrm{d}x_j &amp;= \left(v_j - \lambda x_j - \kappa \sum_{j'\neq j} x_{j'}\right)\mathrm{d}t + \xi \sqrt{\mathrm{d}t}
\quad\text{with}\quad \xi\sim\mathcal{N}(0, 1)\\
x_j &amp;=\mathrm{max}(x_j, 0)
\end{align}
\end{split}\]</div>
<p>This process continues until one of the accumulator’s activations exceeds a fixed threshold <span class="math notranslate nohighlight">\(a\)</span>. The decision corresponding to the accumulator that reached its threshold first will be made. The first-passage time, including a constant shift <span class="math notranslate nohighlight">\(\tau\)</span> for non-decisional processes, determines the response time. For simplicity, we assume that all accumulators start at <span class="math notranslate nohighlight">\(0\)</span>, so we do not account for an <em>a priori</em> bias towards a particular decision alternative. Thus, our LCA version has the following free parameters:</p>
<ul class="simple">
<li><p>Drift rates <span class="math notranslate nohighlight">\(v_j\)</span></p></li>
<li><p>Threshold <span class="math notranslate nohighlight">\(a\)</span></p></li>
<li><p>Non-decision time <span class="math notranslate nohighlight">\(\tau\)</span></p></li>
<li><p>Decay <span class="math notranslate nohighlight">\(\lambda\)</span></p></li>
<li><p>Inhibition <span class="math notranslate nohighlight">\(\kappa\)</span></p></li>
</ul>
<section id="creating-a-simulator">
<h3><span class="section-number">4.3.1. </span>Creating a Simulator <a class="anchor" id="creating_a_simulator"></a><a class="headerlink" href="#creating-a-simulator" title="Link to this heading">#</a></h3>
<p>Now, let us specify the LCA as a randomized data simulator. For this function we use the <code class="docutils literal notranslate"><span class="pre">&#64;njit</span></code> decorator from the <a class="reference external" href="https://numba.pydata.org/">Numba</a> module to speed up simulation time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@njit</span>
<span class="k">def</span> <span class="nf">lca_trial</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">ndt</span><span class="p">,</span> <span class="n">la</span><span class="p">,</span> <span class="n">ka</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mf">1e5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates a response time and choice from the LCA model given a set of parameters.&quot;&quot;&quot;</span>

    <span class="c1"># get number of decision alternatives</span>
    <span class="n">num_alternatives</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="c1"># constant for diffusion process</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dt</span> <span class="o">*</span> <span class="n">s</span><span class="p">)</span>
    <span class="c1"># initialize accumulator activations</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_alternatives</span><span class="p">)</span>
    <span class="c1"># accumulation process</span>
    <span class="n">num_iter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">a</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_iter</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">:</span>
        <span class="c1"># iterate over accumulators</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_alternatives</span><span class="p">):</span>
            <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">la</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">ka</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">+</span> <span class="n">c</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()))</span>
        <span class="n">num_iter</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1"># determine respnose time and choice</span>
    <span class="n">rt</span> <span class="o">=</span> <span class="n">num_iter</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">+</span> <span class="n">ndt</span>
    <span class="k">if</span> <span class="n">num_iter</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">:</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;=</span> <span class="n">a</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">rt</span><span class="p">,</span> <span class="n">resp</span>
</pre></div>
</div>
</div>
</div>
<p>This function returns a single response time and choice. It is generally written and can be used for all decisions between two or more alternatives. Let’s test it in the case of three alterantives with some randomly chosen parameter values. Note: Expect the very first call to the function to take more time due to compilation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rt</span><span class="p">,</span> <span class="n">resp</span> <span class="o">=</span> <span class="n">lca_trial</span><span class="p">(</span><span class="n">v</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">a</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">ndt</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">la</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">ka</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rt</span><span class="p">,</span> <span class="n">resp</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.849 1.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="defining-prior-distributions">
<h3><span class="section-number">4.3.2. </span>Defining Prior Distributions <a class="anchor" id="defining_prior_distributions"></a><a class="headerlink" href="#defining-prior-distributions" title="Link to this heading">#</a></h3>
<p>Next, we specify prior distributions for the LCA parameters. We want to bound all the parameters to possible values. We also want that most of the mass of the prior distributions lies on plausible values we know from domain expertice. All LCA parameters should be positive values. The leak and decay parameter are further bounded within <span class="math notranslate nohighlight">\([0, 1]\)</span>. Thus, we use Gamma distributions for the drift rates, threshold, and non-decision time. For the leak and decay parameter we use Beta distributions.</p>
<p>Further down we will create an experimental context for a hypothetical decision making task between three alternatives and two conditions. Let us imagine that the experimental manipulation is expected to affect only the drift rates. Thus, we need three drift rates (one for each alternative) for each condition, resulting in a total of six separate drift rates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">RNG</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">2023</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">lca_prior</span><span class="p">(</span><span class="n">num_alternatives</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_conditons</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="s2">&quot;Generates a random draw from the joint prior distribution.&quot;</span>

    <span class="n">drifts</span> <span class="o">=</span> <span class="n">RNG</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="mf">1.2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_alternatives</span> <span class="o">*</span> <span class="n">num_conditons</span><span class="p">)</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">RNG</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">ndt</span> <span class="o">=</span> <span class="n">RNG</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="mf">5.0</span><span class="p">)</span>
    <span class="n">decay</span> <span class="o">=</span> <span class="n">RNG</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">inhibition</span> <span class="o">=</span> <span class="n">RNG</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">drifts</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">ndt</span><span class="p">,</span> <span class="n">decay</span><span class="p">,</span> <span class="n">inhibition</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Lets pass our <code class="docutils literal notranslate"><span class="pre">lca_prior</span></code> function to BayesFlow’s <code class="docutils literal notranslate"><span class="pre">Prior</span></code> wrapper.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PARAM_NAMES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sa">r</span><span class="s2">&quot;$v_{1,1}$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$v_{1,2}$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$v_{1,3}$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$v_{2,1}$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$v_{2,2}$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$v_{2,3}$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$a$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$\tau$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$\lambda$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$\kappa$&quot;</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">simulation</span><span class="o">.</span><span class="n">Prior</span><span class="p">(</span><span class="n">prior_fun</span><span class="o">=</span><span class="n">lca_prior</span><span class="p">,</span> <span class="n">param_names</span><span class="o">=</span><span class="n">PARAM_NAMES</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can now sample from our joint prior distribution by calling the prior class with the batch_size argument.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;prior_draws&#39;: array([[2.14202107, 0.37964542, 0.71023643, 1.18597077, 0.81592505,
         1.44358328, 1.68055805, 0.33196847, 0.29361842, 0.17988274]]),
 &#39;batchable_context&#39;: None,
 &#39;non_batchable_context&#39;: None}
</pre></div>
</div>
</div>
</div>
<p>This returns a dictionary containing a single prior draw. In addition to the prior draws the dictionary contains <code class="docutils literal notranslate"><span class="pre">batchable_context</span></code> and <code class="docutils literal notranslate"><span class="pre">non_batchable_context</span></code> keys. These variables allow the prior function to accept context information based on which the behavior of the function can be modified (e.g., for conditional priors). In our use case, we do not have variables that influence the prior function. More details on the functionality and usablity of these context variables follow in the next chapter.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Prior</span></code> wrapper comes with some handy functionalities. For instance, we can simply inspect our prior distributions by plotting some prior draws with the method <code class="docutils literal notranslate"><span class="pre">plot_prior2d()</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">plot_prior2d</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="context-variables-for-general-amortized-inference">
<h3><span class="section-number">4.3.3. </span>Context Variables for General Amortized Inference <a class="anchor" id="context_variables_for"></a><a class="headerlink" href="#context-variables-for-general-amortized-inference" title="Link to this heading">#</a></h3>
<p>A generative model, in addition to prior and simulator, also incorporates various contextual factors that affect the data generation process. These contextual assumptions are often specific to the field of study and can include elements such as experimental conditions, number of observations, and subject-specific factors.</p>
<p><code class="docutils literal notranslate"><span class="pre">BayesFlow</span></code> distinguishes between two types of context variables: <code class="docutils literal notranslate"><span class="pre">batchable_context</span></code> and <code class="docutils literal notranslate"><span class="pre">non_batchable_context</span></code>. This distinction is purely technical, rather then conceptual:</p>
<ul class="simple">
<li><p>Batchable context variables differ for each simulation in each training batch of simulations;</p></li>
<li><p>Non-batchable context variables stay the same for each simulation in a batch, but differ across simulated batches;</p></li>
</ul>
<p>Examples for <strong>batchable</strong> context variables include experimental design variables, design matrices, etc.
Examples for <strong>non-batchable</strong> context variables include the number of observations in an experiment, positional encodings, time indices, etc. While the latter can also be considered batchable in principle, batching them would require non-Tensor (i.e., non-rectangular) data structures, which usually means inefficient computations.</p>
<p>For this tutorial, I want to define one <strong>non-batchable</strong> and one <strong>batchable</strong> context variable that affect the simulator, but not the prior function. Let us imagine a hypothetical three-alternative decision-making task. In this task, two different stimuli are shown. We assume that this experimental manipulation affects the rate of evidence accumulation of the three accumulators. To simulate this experimental manipulation, we can define a function that creates randomly interleaved condition indicators for an experiment with let’s say <span class="math notranslate nohighlight">\(500\)</span> trials. This condition variable is <strong>batchable</strong>, because it will vary for each simulation in a given batch.</p>
<p>In practice, it’s common to encounter missing trials in psychological research due to various reasons such as a participant’s attentional lapses or experimental errors. Therefore, it’s also important to train our networks with a varying number of observations. This approach will make sure that the model can also be fit to data sets with missing data. Let us create a function that randomly samples a number of observations between <span class="math notranslate nohighlight">\(200\)</span> and <span class="math notranslate nohighlight">\(300\)</span>. This condition variable is not batchable, because if we have different number of observations within a batch, then we don’t get a rectangular multi-dimensional array of <code class="docutils literal notranslate"><span class="pre">size=(batch_size,</span> <span class="pre">n_obs,</span> <span class="pre">data_dim)</span></code>.</p>
<p><strong>Important:</strong> Since the posterior will also depend on all context variables, these need to be passed to the inference network through a <code class="docutils literal notranslate"><span class="pre">configurator</span></code> function (described below).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MIN_OBS</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">MAX_OBS</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">NUM_CONDITIONS</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">random_num_obs</span><span class="p">(</span><span class="n">min_obs</span><span class="o">=</span><span class="n">MIN_OBS</span><span class="p">,</span> <span class="n">max_obs</span><span class="o">=</span><span class="n">MAX_OBS</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Draws a random number of observations for all simulations in a batch.&quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">RNG</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">min_obs</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">max_obs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_condition_matrix</span><span class="p">(</span><span class="n">num_obs</span><span class="p">,</span> <span class="n">num_conditons</span><span class="o">=</span><span class="n">NUM_CONDITIONS</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Draws a random design matrix for each simulation in a batch.&quot;&quot;&quot;</span>

    <span class="n">obs_per_condition</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_obs</span> <span class="o">/</span> <span class="n">num_conditons</span><span class="p">)</span>
    <span class="n">condition</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_conditons</span><span class="p">)</span>
    <span class="n">condition</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">obs_per_condition</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">condition</span><span class="p">[:</span><span class="n">num_obs</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let us pass the <code class="docutils literal notranslate"><span class="pre">generate_condition_matrix</span></code> and the <code class="docutils literal notranslate"><span class="pre">random_num_obs</span></code> function to BayesFlow’s <code class="docutils literal notranslate"><span class="pre">ContextGenerator</span></code> wrapper. In order to use the output of the <code class="docutils literal notranslate"><span class="pre">random_num_obs</span></code> function, which is the number of observations, and is needed by the <code class="docutils literal notranslate"><span class="pre">generate_condition_matrix</span></code> function, we have to set the <code class="docutils literal notranslate"><span class="pre">use_non_batchable_for_batchable</span></code> argument to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">context_gen</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">simulation</span><span class="o">.</span><span class="n">ContextGenerator</span><span class="p">(</span>
    <span class="n">non_batchable_context_fun</span><span class="o">=</span><span class="n">random_num_obs</span><span class="p">,</span>
    <span class="n">batchable_context_fun</span><span class="o">=</span><span class="n">generate_condition_matrix</span><span class="p">,</span>
    <span class="n">use_non_batchable_for_batchable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">context_gen</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;non_batchable_context&#39;: 220,
 &#39;batchable_context&#39;: [array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]}
</pre></div>
</div>
</div>
</div>
<p>As you can see, the randomly sampled number of observation is constant within a batch of 2 simulated experimental contexts, but the order of the experimental conditions is different between the contexts.</p>
<p><strong>Important</strong>: Since the model assumes that the observed response times are generated exchangeably (i.e., IID) and we will be using a permutation-invariant <code class="docutils literal notranslate"><span class="pre">DeepSet</span></code> for compressing the simulations, the order of the generated condition indicators is not important. Thus, we don’t need to shuffle the condition indicators, even though these may have a different order in the real data set.</p>
</section>
<section id="simulator">
<h3><span class="section-number">4.3.4. </span>Simulator <a class="anchor" id="simulator"></a><a class="headerlink" href="#simulator" title="Link to this heading">#</a></h3>
<p>Next, we create a function that repeatetly calls the <code class="docutils literal notranslate"><span class="pre">lca_trial</span></code> function to simulate the performance of a single subject in a whole experiment given a set of parameter values and context variables. Again, we use the <code class="docutils literal notranslate"><span class="pre">&#64;njit</span></code> decorator to improve the speed of the core data simulation function, which will be heavily used during training.</p>
<p>Note, that in addition to the vector of parameters, our simulator takes the design matrix (i.e., batchable context) and the number of observations (i.e., non-batchable context) as arguments.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@njit</span>
<span class="k">def</span> <span class="nf">lca_experiment</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">design_matrix</span><span class="p">,</span> <span class="n">num_obs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Simulates data from a single subject in a multi-alternative response times experiment.&quot;&quot;&quot;</span>

    <span class="n">num_alternatives</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="n">NUM_CONDITIONS</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[:</span> <span class="n">num_alternatives</span> <span class="o">*</span> <span class="n">NUM_CONDITIONS</span><span class="p">]</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">NUM_CONDITIONS</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_obs</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_obs</span><span class="p">):</span>
        <span class="n">out</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lca_trial</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="n">design_matrix</span><span class="p">[</span><span class="n">n</span><span class="p">]],</span> <span class="n">theta</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">],</span> <span class="n">theta</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="n">theta</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">theta</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s pass the <code class="docutils literal notranslate"><span class="pre">lca_experiment</span></code> function and the context generator to BayesFlow’s <code class="docutils literal notranslate"><span class="pre">Simulator</span></code> wrapper.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulator</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">simulation</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">simulator_fun</span><span class="o">=</span><span class="n">lca_experiment</span><span class="p">,</span> <span class="n">context_generator</span><span class="o">=</span><span class="n">context_gen</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We have now defined all the building blocks of a generative model, namely a randomized data generator, prior distributions, and a experimental context. We can now combine all the parts to form a generative model by using BayesFlow’s <code class="docutils literal notranslate"><span class="pre">GenerativeModel</span></code> class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">simulation</span><span class="o">.</span><span class="n">GenerativeModel</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;LCA&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:root:Performing 2 pilot runs with the LCA model...
INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 10)
INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 296, 2)
INFO:root:No optional prior non-batchable context provided.
INFO:root:No optional prior batchable context provided.
INFO:root:Shape of simulation non-batchable context: ()
INFO:root:Could not determine shape of simulation batchable context. Type appears to be non-array: &lt;class &#39;list&#39;&gt;,                                    so make sure your input configurator takes cares of that!
</pre></div>
</div>
</div>
</div>
<p>The usage of the <code class="docutils literal notranslate"><span class="pre">Prior</span></code>, <code class="docutils literal notranslate"><span class="pre">Simulator</span></code>, and <code class="docutils literal notranslate"><span class="pre">GenerativeModel</span></code> wrappers is not mandatory. These are only provided for convinience and should cover the basic use cases. You are free to implement your own generative models in any way you want, as long as their outputs can interact with BayesFlow’s objects.</p>
<p>Let us simulate a batch of <span class="math notranslate nohighlight">\(10\)</span> data sets with <span class="math notranslate nohighlight">\(10\)</span> randomly sampled parameter sets and generated contexts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">example_sim</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We get a dictionary with everything we need:</p>
<ul class="simple">
<li><p>Prior draws</p></li>
<li><p>Batchable and non-batchable context for the simulator</p></li>
<li><p>Simulated response times and choice data</p></li>
</ul>
</section>
</section>
<section id="prior-pushforward-check">
<h2><span class="section-number">4.4. </span>Prior Pushforward Check <a class="anchor" id="prior_pushforward_check"></a><a class="headerlink" href="#prior-pushforward-check" title="Link to this heading">#</a></h2>
<p>Now that we have specified a fully-flegded cognitive model, we want to check whether the generative model with its (prior) assumptions produces sensible data that could be oberseved in the real world. To this end, we just simulate some data sets and inspect the joint response time distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="p">,</span> <span class="n">axarr</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axarr</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">example_sim</span><span class="p">[</span><span class="s2">&quot;sim_data&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;maroon&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Simulated RTs (seconds)&quot;</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/17558f30de9f12eead37b8719513802db48c65694733c021ab3aaf0c5f1d7004.png" src="../_images/17558f30de9f12eead37b8719513802db48c65694733c021ab3aaf0c5f1d7004.png" />
</div>
</div>
<p>The model generates skewed RT distributions which are commonly observed in empricial response time experiments. We also do not detect any unusual or implausible values such as negative response times or excessively high values. In practice, you would perform these checks over multiple simulations from the prior predictive and try to distil the information through informative <em>summary statistics</em> of the data. Basically, you are trying to answer the following question: What assumptions do my prior and likelihood specification encode regarding the data-generating process and its typical scope?</p>
<p>The next step in our workflow is to conduct model sensitivity and computational faithfulness checks. This involves fitting our LCA model to simulated data and then using the obtained parameters to predict these data through resimulation. Before we can proceed with this step, we first need to train our neural networks.</p>
</section>
<section id="defining-the-neural-approximator">
<h2><span class="section-number">4.5. </span>Defining the Neural Approximator <a class="anchor" id="defining_the_neural"></a><a class="headerlink" href="#defining-the-neural-approximator" title="Link to this heading">#</a></h2>
<section id="summary-network">
<h3><span class="section-number">4.5.1. </span>Summary Network <a class="anchor" id="summary_network"></a><a class="headerlink" href="#summary-network" title="Link to this heading">#</a></h3>
<p>Although we simulate randomly interleaved experimental manipulation, we are not really interested in any sequential effects during the hypothetical decision task. Therefore, we can treat our data as exchangeable and use a <code class="docutils literal notranslate"><span class="pre">SetTransformer</span></code> for the summary network. This invariant neural network respects the permutation invariance of the data. It takes (at least) 3D tensors of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">n_obs,</span> <span class="pre">data_dim)</span></code> and reduce them to 2D tensors of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">summary_dim)</span></code>, where <code class="docutils literal notranslate"><span class="pre">summary_dim</span></code> is a hyperparameter to be set by us. Heuristically, this number should not be lower than the number of parameters in a model. Below, we create a deep permutation-invariant network with <code class="docutils literal notranslate"><span class="pre">summary_dim=32</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_net</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">SetTransformer</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">summary_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;lca_summary&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">input_dim=5</span></code> setting is due to the fact that the configured data will have <span class="math notranslate nohighlight">\(5\)</span> dimensions (last axis): the continuous RT, the <span class="math notranslate nohighlight">\(3\)</span>-dimensional one-hot encoding of the <span class="math notranslate nohighlight">\(3\)</span> choices, and a binary condition indicator.</p>
</section>
<section id="inference-network">
<h3><span class="section-number">4.5.2. </span>Inference Network <a class="anchor" id="inference_network"></a><a class="headerlink" href="#inference-network" title="Link to this heading">#</a></h3>
<p>The conditional invertible neural network (cINN) is the key component of our amortized posterior inference framework. The only mandatory hyperparameter for the cINN is the number of parameters to be estimated. However, other hyperparameters, such as the number of coupling layers, can also be adjusted and these may be kay for getting the best our of your inference networks. For an actual application, you may want to experiment with these settings on an offline “development” set of simulations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inference_net</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">InvertibleNetwork</span><span class="p">(</span>
    <span class="n">num_params</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">prior</span><span class="o">.</span><span class="n">param_names</span><span class="p">),</span>
    <span class="n">coupling_settings</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dense_args&quot;</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">kernel_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">},</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;lca_inference&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note also, that we are turning off the kernel and dropout regularization for the networks, since we don’t need these for online training (overfitting is impossible if the networks never see the same simulated data set twice during training).</p>
</section>
<section id="amortized-posterior">
<h3><span class="section-number">4.5.3. </span>Amortized Posterior <a class="anchor" id="amortized_posterior"></a><a class="headerlink" href="#amortized-posterior" title="Link to this heading">#</a></h3>
<p>We can now connect the summary and inference networks via the <code class="docutils literal notranslate"><span class="pre">AmortizedPosterior</span></code> wrapper:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">amortizer</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">amortizers</span><span class="o">.</span><span class="n">AmortizedPosterior</span><span class="p">(</span><span class="n">inference_net</span><span class="p">,</span> <span class="n">summary_net</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;lca_amortizer&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="defining-the-configurator">
<h2><span class="section-number">4.6. </span>Defining the Configurator <a class="anchor" id="defining_the_configurator"></a><a class="headerlink" href="#defining-the-configurator" title="Link to this heading">#</a></h2>
<p>A configurator acts as an intermediary between a generative model and an amortizer. Here we should do mainly two things:</p>
<ol class="arabic simple">
<li><p>Bring the output of the generative model (simulated data, context, prior draws) into a suitable format for processing with neural networks.</p></li>
<li><p>Transformations of data and/or parameters.</p></li>
</ol>
<p>In the following we will do both. Firsty, our simulated data sets have two dimensions <code class="docutils literal notranslate"><span class="pre">(n_obs,</span> <span class="pre">data_dim)</span></code>. <code class="docutils literal notranslate"><span class="pre">data_dim</span> <span class="pre">=</span> <span class="pre">2</span></code> consists of response times and choices. The choice variable is categorical and can be either <span class="math notranslate nohighlight">\(0\)</span>, <span class="math notranslate nohighlight">\(1\)</span>, or <span class="math notranslate nohighlight">\(2\)</span>, because there are three alternatives in the imagined decision task. When working with neural networks, categorical variables always have to be one-hot encoded (dummy-coded). In addition, we also have to pass the context information to the neural networks. As we only have two conditions this variable is already dummy coded and we simply append it to the two dimensional data array. This will extend the <code class="docutils literal notranslate"><span class="pre">data_dim</span></code> to <span class="math notranslate nohighlight">\(5\)</span> (one for rts, three for responses, one for context).</p>
<p>Secondly, we also want to standardize the data generating parameters before we pass them to the neural network.</p>
<p>In order to standardize the parameters we need the mean and standard deviation of our prior distributions. We can get them with another handy method from BayesFlow’s <code class="docutils literal notranslate"><span class="pre">prior</span></code> class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior_means</span><span class="p">,</span> <span class="n">prior_stds</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">estimate_means_and_stds</span><span class="p">(</span><span class="n">n_draws</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>
<span class="n">prior_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">prior_means</span><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">prior_stds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">prior_stds</span><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>


<span class="k">def</span> <span class="nf">configurator</span><span class="p">(</span><span class="n">forward_dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Configure the output of the GenerativeModel for a BayesFlow setup.&quot;&quot;&quot;</span>

    <span class="c1"># Prepare placeholder dict</span>
    <span class="n">out_dict</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Extract simulated response times</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">forward_dict</span><span class="p">[</span><span class="s2">&quot;sim_data&quot;</span><span class="p">]</span>

    <span class="c1"># Convert list of condition indicators to a 2D array and add a</span>
    <span class="c1"># trailing dimension of 1, so shape becomes (batch_size, num_obs, 1)</span>
    <span class="c1"># We need this in order to easily concatenate the context with the data</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">forward_dict</span><span class="p">[</span><span class="s2">&quot;sim_batchable_context&quot;</span><span class="p">])[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

    <span class="c1"># One-hot encoding of integer choices</span>
    <span class="n">categorical_resp</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="c1"># Concatenate rt, resp, context</span>
    <span class="n">out_dict</span><span class="p">[</span><span class="s2">&quot;summary_conditions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">],</span> <span class="n">categorical_resp</span><span class="p">,</span> <span class="n">context</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Make inference network aware of varying numbers of trials</span>
    <span class="c1"># We create a vector of shape (batch_size, 1) by repeating the sqrt(num_obs)</span>
    <span class="n">vec_num_obs</span> <span class="o">=</span> <span class="n">forward_dict</span><span class="p">[</span><span class="s2">&quot;sim_non_batchable_context&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">out_dict</span><span class="p">[</span><span class="s2">&quot;direct_conditions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">vec_num_obs</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Get data generating parameters</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">forward_dict</span><span class="p">[</span><span class="s2">&quot;prior_draws&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Standardize parameters</span>
    <span class="n">out_dict</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">params</span> <span class="o">-</span> <span class="n">prior_means</span><span class="p">)</span> <span class="o">/</span> <span class="n">prior_stds</span>

    <span class="k">return</span> <span class="n">out_dict</span>
</pre></div>
</div>
</div>
</div>
<p>Our <code class="docutils literal notranslate"><span class="pre">configurator</span></code> returns a pre-processed dictionary with three keys:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">parameters</span></code> - These are the quantities over which we want to perform posterior inference.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">summary_conditions</span></code> - These are the quantities that go into the summary network (i.e., data and further context) before being passed as a condition for the inference network.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">direct_conditions</span></code> - These are the quantities that bypass the summary network and are passed directly as conditions for the inference network.</p></li>
</ol>
<p>In other words, <code class="docutils literal notranslate"><span class="pre">direct_conditions</span></code> will simply be concatenated to the summary network outputs so the final condition vector for the inference network is <code class="docutils literal notranslate"><span class="pre">(summary_net_outputs,</span> <span class="pre">direct_conditions)</span></code>. Note, that you can also use only <code class="docutils literal notranslate"><span class="pre">summary_conditions</span></code> in case there are no direct ones, or only <code class="docutils literal notranslate"><span class="pre">direct_conditions</span></code> in case you are working with data that does not benefit from compression.</p>
</section>
<section id="defining-the-trainer">
<h2><span class="section-number">4.7. </span>Defining the Trainer <a class="anchor" id="defining_the_trainer"></a><a class="headerlink" href="#defining-the-trainer" title="Link to this heading">#</a></h2>
<p>Now, it is time to define the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> instance. We simply pass the generatvie model, the amortizer, and our configurator. Usually, we want to define a <code class="docutils literal notranslate"><span class="pre">checkpoint_path</span></code>, so the neural approximator will be saved automatically to this path and will be loaded the next time you create the <code class="docutils literal notranslate"><span class="pre">trainer</span></code>. Otherwise, neural approximators must be manually saved using, for instance, TensorFlow’s <code class="docutils literal notranslate"><span class="pre">amortizer.save_weights()</span></code> method, or separately saving the summary and inference networks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">trainers</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">generative_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">amortizer</span><span class="o">=</span><span class="n">amortizer</span><span class="p">,</span> <span class="n">configurator</span><span class="o">=</span><span class="n">configurator</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="o">=</span><span class="s2">&quot;lca_model&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:root:Initialized empty loss history.
INFO:root:Initialized networks from scratch.
INFO:root:Performing a consistency check with provided components...
2023-07-16 10:34:27.249261: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200
INFO:root:Done.
</pre></div>
</div>
</div>
</div>
<p>When we initiate the trainer it informs us whether a consistency check (i.e., simulation -&gt; configuration -&gt; transformation -&gt; loss computation) was successful. In our case, we passed the check and are now ready to train our neural networks.</p>
<p>We can also check out the number of trainable neural network parameters for the composite approximator:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">amortizer</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;lca_amortizer&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lca_inference (InvertibleNe  multiple                 531816    
 twork)                                                          
                                                                 
 lca_summary (SetTransformer  multiple                 63608     
 )                                                               
                                                                 
=================================================================
Total params: 595,424
Trainable params: 595,304
Non-trainable params: 120
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-phase">
<h2><span class="section-number">4.8. </span>Training Phase <a class="anchor" id="training_phase"></a><a class="headerlink" href="#training-phase" title="Link to this heading">#</a></h2>
<p>With the help of <code class="docutils literal notranslate"><span class="pre">numba</span></code> our simulator is relatively fast. Thus, we can safely go with online training. Let’s glean the time taken for a batch of <span class="math notranslate nohighlight">\(32\)</span> simulations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 509 ms, sys: 0 ns, total: 509 ms
Wall time: 507 ms
</pre></div>
</div>
</div>
</div>
<p>We will train for <span class="math notranslate nohighlight">\(60\)</span> epochs using <span class="math notranslate nohighlight">\(500\)</span> iterations of <span class="math notranslate nohighlight">\(16\)</span> simulations which amounts to a total of <span class="math notranslate nohighlight">\(60 \times 500 \times 16 = 480000\)</span> simulations. Note, that since we are using online training and the network never sees the same simulated data set twice, overfitting is highly unlikely. Otherwise, we recommend using a validation set of simulations through the <code class="docutils literal notranslate"><span class="pre">validation_sims</span></code> keyword argument and leaving the default regularization. Beware, that training will take a couple of hours due to the inefficient online LCA simulator. Still, keep in mind that we are learning an amortized posterior over the <strong>entire prior predictive distribution of the LCA model</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train_online</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">iterations_per_epoch</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Following our online simulation-based training, we can quickly visualize the loss trajectory using the <code class="docutils literal notranslate"><span class="pre">plot_losses</span></code> function from the <code class="docutils literal notranslate"><span class="pre">diagnostics</span></code> module.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/57830d9e2580d7570797a3fc0c762438f98bac64c6c854993be5c08be7b57feb.png" src="../_images/57830d9e2580d7570797a3fc0c762438f98bac64c6c854993be5c08be7b57feb.png" />
</div>
</div>
<p>At some point around training step <span class="math notranslate nohighlight">\(25000\)</span>, the loss stopped decreasing, indicating that there is not much to learn from further simulation and we can continue with some diagnostics. Thus, if we wanted to increase performance at this point, we would probably make the networks more expressive than train with more simulations.</p>
<p>Let us now proceed with our amortized Bayesian workflow.</p>
</section>
<section id="validation">
<h2><span class="section-number">4.9. </span>Validation <a class="anchor" id="validation"></a><a class="headerlink" href="#validation" title="Link to this heading">#</a></h2>
<section id="simulation-based-calibration">
<h3><span class="section-number">4.9.1. </span>Simulation-Based Calibration <a class="anchor" id="simulation_based_calibration"></a><a class="headerlink" href="#simulation-based-calibration" title="Link to this heading">#</a></h3>
<p>As a small world (i.e. before seeing real data) sanity check, we could test the computational faithfulness of our model - neural network combination. We do this with simulation-based calibration (SBC; for more details see, <a class="reference external" href="https://arxiv.org/abs/1804.06788">Talts et al. 2018</a>; <a class="reference external" href="https://arxiv.org/abs/2103.10522">Säilynoja et al. 2021</a>).</p>
<p>Again, <code class="docutils literal notranslate"><span class="pre">BayesFlow</span></code> has us covered with some pre-packaged functions to compute and visualize the calibration.</p>
<p>For SBC, I always opt for at least a 10:1 ratio between number of simulations and number of posterior samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate some validation data</span>
<span class="n">validation_sims</span> <span class="o">=</span> <span class="n">configurator</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>

<span class="c1"># Extract unstandardized prior draws and transform to original scale</span>
<span class="n">prior_samples</span> <span class="o">=</span> <span class="n">validation_sims</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">prior_stds</span> <span class="o">+</span> <span class="n">prior_means</span>
</pre></div>
</div>
</div>
</div>
<p>Note, that our generative model is simulating data sets with a random number of trials:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Estimation will be performed on data sets with </span><span class="si">{</span><span class="n">validation_sims</span><span class="p">[</span><span class="s1">&#39;summary_conditions&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> simulated trials.&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Estimation will be performed on data sets with 257 simulated trials
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate 100 posterior draws for each of the 1000 simulated data sets</span>
<span class="n">post_samples</span> <span class="o">=</span> <span class="n">amortizer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">validation_sims</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Unstandardize posterior draws into original scale</span>
<span class="n">post_samples</span> <span class="o">=</span> <span class="n">post_samples</span> <span class="o">*</span> <span class="n">prior_stds</span> <span class="o">+</span> <span class="n">prior_means</span>
</pre></div>
</div>
</div>
</div>
<p>Note, that this is the moment where <strong>amortized inference</strong> really shines. We were able to perform posterior inference on <span class="math notranslate nohighlight">\(1000\)</span> data sets within a matter of seconds.</p>
<p><strong>Rank Histograms</strong></p>
<p>If we are able to obtain unbiased posterior distributions, we should observe approximately uniform rank statistic histograms</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plot_sbc_histograms</span><span class="p">(</span><span class="n">post_samples</span><span class="p">,</span> <span class="n">prior_samples</span><span class="p">,</span> <span class="n">num_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">param_names</span><span class="o">=</span><span class="n">PARAM_NAMES</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:root:The ratio of simulations / posterior draws should be &gt; 20 for reliable variance reduction, but your ratio is 10.                    Confidence intervals might be unreliable!
</pre></div>
</div>
<img alt="../_images/7b869ec9e9ee96ecff671499fc0c0997dbcc2d257261b497cfe1b331770ceced.png" src="../_images/7b869ec9e9ee96ecff671499fc0c0997dbcc2d257261b497cfe1b331770ceced.png" />
</div>
</div>
<p><strong>Rank ECDFs</strong></p>
<p>The <code class="docutils literal notranslate"><span class="pre">num_bins</span></code> hyperparameter for the construction of SBC rank histograms can be difficult to choose, despite existing heuristics. An alternative diagnostic approach for calibration is through empirical cumulative distribution functions (ECDF) of rank statistics.</p>
<p>Using the <code class="docutils literal notranslate"><span class="pre">difference=True</span></code> parameter, we can tell the function to compute ECDF differences for a more dynamic visualization range.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plot_sbc_ecdf</span><span class="p">(</span><span class="n">post_samples</span><span class="p">,</span> <span class="n">prior_samples</span><span class="p">,</span> <span class="n">stacked</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">difference</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">param_names</span><span class="o">=</span><span class="n">PARAM_NAMES</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/4f9af409aa2e7eb29dcfe1446dc4a81e97e20ba7c31608d00717c437d9ebca1e.png" src="../_images/4f9af409aa2e7eb29dcfe1446dc4a81e97e20ba7c31608d00717c437d9ebca1e.png" />
</div>
</div>
<p>Hooray, both methods indicate that our approximator is more or less well calibrated!</p>
</section>
<section id="model-sensitivity">
<h3><span class="section-number">4.9.2. </span>Model Sensitivity <a class="anchor" id="model_sensitivity"></a><a class="headerlink" href="#model-sensitivity" title="Link to this heading">#</a></h3>
<p>Being able to recover the true data generating parameters is very important in cognitive modeling. If a parameter cannot be recovered with reasonable precision of some posterior expectation (e.g., the mean), then we are not allowed to make any psychological interpretation based on the estimate of this parameter. Further, we can consider to remove this parameter from the model.</p>
<p>We can test this <em>in silico</em> via the <code class="docutils literal notranslate"><span class="pre">plot_recovery</span></code> function in the <code class="docutils literal notranslate"><span class="pre">diagnostics</span></code> module. For instance, we can compare how well posterior means recover the true parameter. Below, we re-use the <span class="math notranslate nohighlight">\(1000\)</span> simulations we generated for computing the rank ECDFs, but obtain a larger number of posterior draws per data set for more stable results:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">post_samples</span> <span class="o">=</span> <span class="n">amortizer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">validation_sims</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">post_samples</span> <span class="o">=</span> <span class="n">post_samples</span> <span class="o">*</span> <span class="n">prior_stds</span> <span class="o">+</span> <span class="n">prior_means</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plot_recovery</span><span class="p">(</span>
    <span class="n">post_samples</span><span class="p">,</span> <span class="n">prior_samples</span><span class="p">,</span> <span class="n">param_names</span><span class="o">=</span><span class="n">prior</span><span class="o">.</span><span class="n">param_names</span><span class="p">,</span> <span class="n">point_agg</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">uncertainty_agg</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">std</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/69b4399d9203df66049063eb5ccae6e2a638c236865e9a55d397fdc65420769c.png" src="../_images/69b4399d9203df66049063eb5ccae6e2a638c236865e9a55d397fdc65420769c.png" />
</div>
</div>
<p>All parameters but the decay parameter <span class="math notranslate nohighlight">\(\lambda\)</span> and the inhibition parameter <span class="math notranslate nohighlight">\(\kappa\)</span> can be recovered with reasonable precision by the posterior median. This is not a surprising result, as studies have shown that <span class="math notranslate nohighlight">\(\lambda\)</span> and <span class="math notranslate nohighlight">\(\kappa\)</span> are notoriously hard to recover. Also, we see that large parameter values are hard to recover with sufficient precision, since model sensitivity probably saturates at these values (i.e., the difference in simulator outputs between a threshold <span class="math notranslate nohighlight">\(a = 1\)</span> and <span class="math notranslate nohighlight">\(a = 2\)</span> is more noticeable than the one between <span class="math notranslate nohighlight">\(a = 3\)</span> and <span class="math notranslate nohighlight">\(a = 4\)</span>.</p>
<p><strong>Idea</strong>: Feel free to inspect point recovery with respect to a different summary of the posterior, for instance, the default posterior median and median absolute deviation (MAD).</p>
<p>We can look at model sensitivity more closely via another function which will plot the posterior <span class="math notranslate nohighlight">\(z\)</span>-score vs. the posterior contraction for each marginal posterior.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plot_z_score_contraction</span><span class="p">(</span><span class="n">post_samples</span><span class="p">,</span> <span class="n">prior_samples</span><span class="p">,</span> <span class="n">param_names</span><span class="o">=</span><span class="n">prior</span><span class="o">.</span><span class="n">param_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/28e121d1e3768223aa93903a06d5cd08d8e40eef6ff1e3e73f2d1551aa38c368.png" src="../_images/28e121d1e3768223aa93903a06d5cd08d8e40eef6ff1e3e73f2d1551aa38c368.png" />
</div>
</div>
</section>
<section id="posterior-retrodictive-checks-in-silico">
<h3><span class="section-number">4.9.3. </span>Posterior Retrodictive Checks in Silico <a class="anchor" id="posterior_retrodictive_checks"></a><a class="headerlink" href="#posterior-retrodictive-checks-in-silico" title="Link to this heading">#</a></h3>
<p>Alright, let us now gauge the predictive performance of our model. To this end, we do the following steps:</p>
<ol class="arabic simple">
<li><p>Simulate data with our generative model.</p></li>
<li><p>Fit the model to these data.</p></li>
<li><p>Resimulate new data with samples from the obtained posterior.</p></li>
<li><p>Compare (summary of) the simulated data and the resimulated data (model prediction).</p></li>
</ol>
<p>Note, that is exactly the same procedure as you would do to check the generative performance of your model on experimental data, except that we use simulated instead of empirical data. We explicitly use the term “retrodictive” to indiate that we are not predicting new data, but merely assessing the ability of the posterior model to recreate the data it was fitted on.</p>
<p>We will assess retrodictive performance on <span class="math notranslate nohighlight">\(8\)</span> simulated data sets, but, typically, you would use a much larger number and summarize the results both graphically and numerically. For each synthetic data set, we will draw <span class="math notranslate nohighlight">\(1000\)</span> parameter configurations from the amortized posterior and resimulate data with <span class="math notranslate nohighlight">\(50\)</span> parameter sets randomly sub-sampled from the full set of posterior draws.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define re-simulation settings</span>
<span class="n">num_sim</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">num_resim</span> <span class="o">=</span> <span class="mi">50</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 1</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Simulate and configure data</span>
<span class="n">sim_data</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">num_sim</span><span class="p">)</span>
<span class="n">conf_data</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">configurator</span><span class="p">(</span><span class="n">sim_data</span><span class="p">)</span>
<span class="n">num_obs</span> <span class="o">=</span> <span class="n">sim_data</span><span class="p">[</span><span class="s2">&quot;sim_data&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 2</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit model -&gt; draw 1000 posterior samples per data set</span>
<span class="n">post_samples</span> <span class="o">=</span> <span class="n">amortizer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">conf_data</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>
<span class="c1"># Unstandardize posteriors draws into original scale</span>
<span class="n">post_samples_not_z</span> <span class="o">=</span> <span class="n">post_samples</span> <span class="o">*</span> <span class="n">prior_stds</span> <span class="o">+</span> <span class="n">prior_means</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 3</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate random index for posterior parameter set selection</span>
<span class="n">index_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_samples</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">num_resim</span><span class="p">)</span>

<span class="c1"># Get context of simulated data sets</span>
<span class="n">context</span> <span class="o">=</span> <span class="n">sim_data</span><span class="p">[</span><span class="s2">&quot;sim_batchable_context&quot;</span><span class="p">]</span>

<span class="c1"># Re-simulate</span>
<span class="n">pred_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_sim</span><span class="p">,</span> <span class="n">num_resim</span><span class="p">,</span> <span class="n">num_obs</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sim</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">index_set</span><span class="p">):</span>
        <span class="n">pred_data</span><span class="p">[</span><span class="n">sim</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lca_experiment</span><span class="p">(</span><span class="n">post_samples_not_z</span><span class="p">[</span><span class="n">sim</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="p">:],</span> <span class="n">context</span><span class="p">[</span><span class="n">sim</span><span class="p">],</span> <span class="n">num_obs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 4</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="p">,</span> <span class="n">axarr</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axarr</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span>
        <span class="n">conf_data</span><span class="p">[</span><span class="s2">&quot;summary_conditions&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Simulated data&quot;</span>
    <span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">pred_data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;maroon&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Predicted data&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Simulated data set #</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="c1"># Set legend to first plot</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="c1"># Set x label to bottom row</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">num_sim</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Response time (seconds)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/701ba14415375c262eae932f7b66e3f3382057c3a5f28a3d64b3b69299b1c9d2.png" src="../_images/701ba14415375c262eae932f7b66e3f3382057c3a5f28a3d64b3b69299b1c9d2.png" />
</div>
</div>
<p>Comparing the kernel densities between the simulated and predicted response times, we see that we can fit synthetic data decently, but not satisfactorily. In practice, you would try to find good metrics that summarize such results (over a much larger number of simulations) numerically, in addition to the graphical checks.</p>
<p>At this point, you will proceed by applying your networks to actually observed data.</p>
</section>
</section>
<section id="inference-phase">
<h2><span class="section-number">4.10. </span>Inference Phase <a class="anchor" id="inference_phase"></a><a class="headerlink" href="#inference-phase" title="Link to this heading">#</a></h2>
<p>The next step would usually be to fit the model to real empirical data and check whether the model accurately predicts the data at hand. To this end, we perform posterior retrodiction checks. As I do not have empirical data for a 3 three alternative decision-making task, I will cover the steps of the inference phase on a conceptual level.</p>
<ol class="arabic simple">
<li><p>Read in the data.</p></li>
<li><p>Bring the data into the same form as the simulated data we used for training the network. In our case this would mean, a multi-dimensional array with <code class="docutils literal notranslate"><span class="pre">shape</span> <span class="pre">=</span> <span class="pre">(n_sub,</span> <span class="pre">n_obs,</span> <span class="pre">5)</span></code>. The last dimension should be in the following order: Response time, one-hot encoded choice, condition.</p></li>
<li><p>Split the data into “training” and “test” parts.</p></li>
<li><p>Fit the model to the training data.</p></li>
<li><p>Re-simulate synthetic data with the posterior samples obtained in Step 4 and compare with the training data. This is your indicator of how good the model can reproduce the data it was fitted on.</p></li>
<li><p>Re-simulate further synthetic data and comapre it with the test data (not used for estimating the posterior). This is your indicator of how good the model can predict iunseen data.</p></li>
<li><p>Create awesome visualizations.</p></li>
</ol>
</section>
<section id="further-experimentation">
<h2><span class="section-number">4.11. </span>Further Experimentation <a class="anchor" id="further_experimentation"></a><a class="headerlink" href="#further-experimentation" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Currently, we have only performed our small world checks for a randomly samples number of trials. Test model sensitivity for the lowest and the highest number of trials. What do you observe? Which parameters are most sensitive to increasing number of observations?</p></li>
<li><p>Try a two-step learning approach. First, generate an offline data set with a very small number of trials and train the networks until convergence. Then, continue training using online learning with realistic numbers of trials. How does this approach perform compared? Do you get faster training and similar performance?</p></li>
<li><p>Change the <code class="docutils literal notranslate"><span class="pre">SetTransformer</span></code> to a <code class="docutils literal notranslate"><span class="pre">DeepSet</span></code> architecture. Does the one summary network type perform better than the other?</p></li>
<li><p>Change the <code class="docutils literal notranslate"><span class="pre">coupling_design</span></code> argument of the <code class="docutils literal notranslate"><span class="pre">InvertibleNetwork</span></code> to <code class="docutils literal notranslate"><span class="pre">spline</span></code> and re-train. Can you get better uncertainty reduction and more precise point estimates?</p></li>
</ol>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Model_Misspecification.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Detecting Model Misspecification in Amortized Posterior Inference</p>
      </div>
    </a>
    <a class="right-next"
       href="Linear_ODE_system.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Posterior Estimation for ODEs</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-contents">4.1. Table of Contents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">4.2. Introduction <a class="anchor" id="introduction"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-model-specification">4.3. Generative Model Specification <a class="anchor" id="generative_model_specification"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-simulator">4.3.1. Creating a Simulator <a class="anchor" id="creating_a_simulator"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-prior-distributions">4.3.2. Defining Prior Distributions <a class="anchor" id="defining_prior_distributions"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#context-variables-for-general-amortized-inference">4.3.3. Context Variables for General Amortized Inference <a class="anchor" id="context_variables_for"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulator">4.3.4. Simulator <a class="anchor" id="simulator"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-pushforward-check">4.4. Prior Pushforward Check <a class="anchor" id="prior_pushforward_check"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-neural-approximator">4.5. Defining the Neural Approximator <a class="anchor" id="defining_the_neural"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-network">4.5.1. Summary Network <a class="anchor" id="summary_network"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-network">4.5.2. Inference Network <a class="anchor" id="inference_network"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#amortized-posterior">4.5.3. Amortized Posterior <a class="anchor" id="amortized_posterior"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-configurator">4.6. Defining the Configurator <a class="anchor" id="defining_the_configurator"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-trainer">4.7. Defining the Trainer <a class="anchor" id="defining_the_trainer"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-phase">4.8. Training Phase <a class="anchor" id="training_phase"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#validation">4.9. Validation <a class="anchor" id="validation"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-based-calibration">4.9.1. Simulation-Based Calibration <a class="anchor" id="simulation_based_calibration"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-sensitivity">4.9.2. Model Sensitivity <a class="anchor" id="model_sensitivity"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-retrodictive-checks-in-silico">4.9.3. Posterior Retrodictive Checks in Silico <a class="anchor" id="posterior_retrodictive_checks"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-phase">4.10. Inference Phase <a class="anchor" id="inference_phase"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-experimentation">4.11. Further Experimentation <a class="anchor" id="further_experimentation"></a></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Author name not set
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023, BayesFlow authors (lead maintainer: Stefan T. Radev).
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>