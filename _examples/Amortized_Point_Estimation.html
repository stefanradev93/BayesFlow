
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Likelihood-Free Parameter Estimation with Neural Bayes Estimators - BayesFlow edition &#8212; BayesFlow: Amortized Bayesian Inference</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_examples/Amortized_Point_Estimation';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://www.bayesflow.org/_examples/Amortized_Point_Estimation.html" />
    <link rel="icon" href="../_static/bayesflow_hex.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/bayesflow_hex.png" class="logo__image only-light" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
    <script>document.write(`<img src="../_static/bayesflow_hex.png" class="logo__image only-dark" alt="BayesFlow: Amortized Bayesian Inference - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../index.html">BayesFlow</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../examples.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Intro_Amortized_Posterior_Estimation.html">1. Quickstart: Amortized Posterior Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="TwoMoons_Bimodal_Posterior.html">2. Two Moons: Tackling Bimodal Posteriors</a></li>
<li class="toctree-l2"><a class="reference internal" href="Model_Misspecification.html">3. Detecting Model Misspecification in Amortized Posterior Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="LCA_Model_Posterior_Estimation.html">4. Principled Amortized Bayesian Workflow for Cognitive Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="Linear_ODE_system.html">5. Posterior Estimation for ODEs</a></li>
<li class="toctree-l2"><a class="reference internal" href="Covid19_Initial_Posterior_Estimation.html">6. Posterior Estimation for SIR-like Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="Model_Comparison_MPT.html">7. Model Comparison for Cognitive Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="Hierarchical_Model_Comparison_MPT.html">8. Hierarchical Model Comparison for Cognitive Models</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/bayesflow.html">Public API: bayesflow package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/bayesflow.benchmarks.html">bayesflow.benchmarks package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.bernoulli_glm.html">bayesflow.benchmarks.bernoulli_glm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.bernoulli_glm_raw.html">bayesflow.benchmarks.bernoulli_glm_raw module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.gaussian_linear.html">bayesflow.benchmarks.gaussian_linear module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.gaussian_linear_uniform.html">bayesflow.benchmarks.gaussian_linear_uniform module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.gaussian_mixture.html">bayesflow.benchmarks.gaussian_mixture module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.inverse_kinematics.html">bayesflow.benchmarks.inverse_kinematics module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.lotka_volterra.html">bayesflow.benchmarks.lotka_volterra module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.sir.html">bayesflow.benchmarks.sir module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.slcp.html">bayesflow.benchmarks.slcp module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.slcp_distractors.html">bayesflow.benchmarks.slcp_distractors module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.two_moons.html">bayesflow.benchmarks.two_moons module</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.amortizers.html">bayesflow.amortizers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.attention.html">bayesflow.attention module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.coupling_networks.html">bayesflow.coupling_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.diagnostics.html">bayesflow.diagnostics module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.inference_networks.html">bayesflow.inference_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.losses.html">bayesflow.losses module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.networks.html">bayesflow.networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.sensitivity.html">bayesflow.sensitivity module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.simulation.html">bayesflow.simulation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.summary_networks.html">bayesflow.summary_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.trainers.html">bayesflow.trainers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.configuration.html">bayesflow.configuration module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.default_settings.html">bayesflow.default_settings module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.computational_utilities.html">bayesflow.computational_utilities module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.helper_classes.html">bayesflow.helper_classes module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.helper_functions.html">bayesflow.helper_functions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.helper_networks.html">bayesflow.helper_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.exceptions.html">bayesflow.exceptions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.mcmc.html">bayesflow.mcmc module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.version.html">bayesflow.version module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.wrappers.html">bayesflow.wrappers module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/bayesflow.experimental.html">bayesflow.experimental package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.experimental.rectifiers.html">bayesflow.experimental.rectifiers module</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Full Installation Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to BayesFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About us</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/stefanradev93/BayesFlow" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/stefanradev93/BayesFlow/edit/master/_examples/Amortized_Point_Estimation.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/stefanradev93/BayesFlow/issues/new?title=Issue%20on%20page%20%2F_examples/Amortized_Point_Estimation.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/_examples/Amortized_Point_Estimation.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Likelihood-Free Parameter Estimation with Neural Bayes Estimators - BayesFlow edition</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-benchmark-from-the-bayesflow-benchmark-suite-gaussian-linear">Simple Benchmark from the BayesFlow Benchmark Suite: Gaussian Linear</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#illustrative-example-from-the-paper">Illustrative Example from the Paper</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_probability</span> <span class="k">as</span> <span class="nn">tfp</span>

<span class="kn">import</span> <span class="nn">bayesflow</span> <span class="k">as</span> <span class="nn">bf</span>
<span class="kn">from</span> <span class="nn">bayesflow.amortizers</span> <span class="kn">import</span> <span class="n">AmortizedPointEstimator</span>
<span class="kn">from</span> <span class="nn">bayesflow.benchmarks</span> <span class="kn">import</span> <span class="n">Benchmark</span>
<span class="kn">from</span> <span class="nn">bayesflow.helper_networks</span> <span class="kn">import</span> <span class="n">ConfigurableMLP</span>
<span class="kn">from</span> <span class="nn">bayesflow.simulation</span> <span class="kn">import</span> <span class="n">GenerativeModel</span><span class="p">,</span> <span class="n">Prior</span><span class="p">,</span> <span class="n">Simulator</span>
<span class="kn">from</span> <span class="nn">bayesflow.summary_networks</span> <span class="kn">import</span> <span class="n">DeepSet</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-03-09 18:24:43.041573: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2024-03-09 18:24:43.070746: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-03-09 18:24:43.070814: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-03-09 18:24:43.071908: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-03-09 18:24:43.077695: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2024-03-09 18:24:43.078655: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-09 18:24:44.113298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/data/Programming/IWR/BayesFlow/bayesflow/trainers.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from tqdm.autonotebook import tqdm
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="likelihood-free-parameter-estimation-with-neural-bayes-estimators-bayesflow-edition">
<h1>Likelihood-Free Parameter Estimation with Neural Bayes Estimators - BayesFlow edition<a class="headerlink" href="#likelihood-free-parameter-estimation-with-neural-bayes-estimators-bayesflow-edition" title="Link to this heading">#</a></h1>
<p>In this notebook, we will demonstrate how to learn amortized neural Bayes estimators, as decribed in the following <a class="reference external" href="https://www.tandfonline.com/doi/full/10.1080/00031305.2023.2249522">paper</a>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Sainsbury-Dale, M., Zammit-Mangion, A., &amp; Huser, R. (2024).
Likelihood-free parameter estimation with neural Bayes estimators.
The American Statistician, 78(1), 1-14.
</pre></div>
</div>
<p>We will use BayesFlow’s <code class="docutils literal notranslate"><span class="pre">AmortizedPointEstimator</span></code> class. There are two main differences to learning the full posterior distribution:</p>
<p>a) result: instead of samples from a distribution, we obtain one value per data set
b) network: instead of mapping from parameter space to latent space, with the (summarized) data as a condition, we directly map from the data to the parameter space</p>
<p>For a), we can leverage other means of uncertainty quantification, i.e. bootstrapping methods. For b), we just have to adapt the network input and output dimensions for the interference network accordingly. Here, we will use a simple MLP with residual connections in the hidden block, <code class="docutils literal notranslate"><span class="pre">ConfigurableMLP</span></code>.</p>
<section id="simple-benchmark-from-the-bayesflow-benchmark-suite-gaussian-linear">
<h2>Simple Benchmark from the BayesFlow Benchmark Suite: Gaussian Linear<a class="headerlink" href="#simple-benchmark-from-the-bayesflow-benchmark-suite-gaussian-linear" title="Link to this heading">#</a></h2>
<p>To get familiar with the API, we start with a simple toy example with a 10-dimensional Gaussian likelihood. We use multiple observations <code class="docutils literal notranslate"><span class="pre">&quot;n_obs&quot;</span></code> and summarize them using a standard <code class="docutils literal notranslate"><span class="pre">DeepSet</span></code>, which outputs <code class="docutils literal notranslate"><span class="pre">summary_dim</span></code> values. The loss function can be configured in two ways. If <code class="docutils literal notranslate"><span class="pre">loss_fun</span></code> is passed, the supplied function serves as the loss. As a shorthand, if <code class="docutils literal notranslate"><span class="pre">norm_ord</span></code> is passed, the <code class="docutils literal notranslate"><span class="pre">tf.norm</span></code> function is used and <code class="docutils literal notranslate"><span class="pre">norm_ord</span></code> is passed as its <code class="docutils literal notranslate"><span class="pre">ord</span></code> argument.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">benchmark</span> <span class="o">=</span> <span class="n">Benchmark</span><span class="p">(</span><span class="s2">&quot;gaussian_linear&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;posterior&quot;</span><span class="p">,</span> <span class="n">sim_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;n_obs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">})</span>

<span class="c1"># Summary network to jointly learn summary statistics</span>
<span class="n">summary_dim</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">summary_net</span> <span class="o">=</span> <span class="n">DeepSet</span><span class="p">(</span><span class="n">summary_dim</span><span class="p">)</span>

<span class="c1"># An easy-to-use MLP with residual connections</span>
<span class="n">inference_net</span> <span class="o">=</span> <span class="n">ConfigurableMLP</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">summary_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

<span class="c1"># Can be any norm in [1, 2, np.inf] and can also use a summary network</span>
<span class="n">amortizer</span> <span class="o">=</span> <span class="n">AmortizedPointEstimator</span><span class="p">(</span><span class="n">inference_net</span><span class="p">,</span> <span class="n">summary_net</span><span class="o">=</span><span class="n">summary_net</span><span class="p">,</span> <span class="n">norm_ord</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:root:Performing 2 pilot runs with the gaussian_linear model...
INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 10)
INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 10, 10)
INFO:root:No optional prior non-batchable context provided.
INFO:root:No optional prior batchable context provided.
INFO:root:No optional simulation non-batchable context provided.
INFO:root:No optional simulation batchable context provided.
</pre></div>
</div>
</div>
</div>
<p>Next, we have to provide a configurator, to assure that the data is first passed to the <em>summary network</em>, and not directly to the inference network</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">config</span><span class="p">(</span><span class="n">forward_dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper function for posterior configuration.&quot;&quot;&quot;</span>

    <span class="n">input_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forward_dict</span><span class="p">[</span><span class="s2">&quot;prior_draws&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># we use &quot;summary_conditions&quot; and not &quot;direct_conditions&quot; to pass the data</span>
    <span class="c1"># to the summary network</span>
    <span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;summary_conditions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forward_dict</span><span class="p">[</span><span class="s2">&quot;sim_data&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_dict</span>
</pre></div>
</div>
</div>
</div>
<p>Training can happen as usual. Here we use offline training, but online training can be used as well (see the next section for an example).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Training can happen as usual</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">trainers</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">amortizer</span><span class="o">=</span><span class="n">amortizer</span><span class="p">,</span> <span class="n">configurator</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">generative_model</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:root:Trainer initialization: No generative model provided. Only offline learning mode is available!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train_offline</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training epoch 1: 100%|██████████| 157/157 [00:04&lt;00:00, 36.20it/s, Epoch: 1, Batch: 157,Loss: 0.243,Avg.Loss: 0.253,LR: 4.88E-04] 
Training epoch 2: 100%|██████████| 157/157 [00:00&lt;00:00, 167.05it/s, Epoch: 2, Batch: 157,Loss: 0.157,Avg.Loss: 0.195,LR: 4.53E-04]
Training epoch 3: 100%|██████████| 157/157 [00:00&lt;00:00, 164.13it/s, Epoch: 3, Batch: 157,Loss: 0.153,Avg.Loss: 0.165,LR: 3.97E-04]
Training epoch 4: 100%|██████████| 157/157 [00:00&lt;00:00, 166.40it/s, Epoch: 4, Batch: 157,Loss: 0.142,Avg.Loss: 0.145,LR: 3.28E-04]
Training epoch 5: 100%|██████████| 157/157 [00:00&lt;00:00, 157.45it/s, Epoch: 5, Batch: 157,Loss: 0.149,Avg.Loss: 0.135,LR: 2.51E-04]
Training epoch 6: 100%|██████████| 157/157 [00:01&lt;00:00, 156.19it/s, Epoch: 6, Batch: 157,Loss: 0.122,Avg.Loss: 0.131,LR: 1.73E-04]
Training epoch 7: 100%|██████████| 157/157 [00:00&lt;00:00, 157.46it/s, Epoch: 7, Batch: 157,Loss: 0.113,Avg.Loss: 0.128,LR: 1.03E-04]
Training epoch 8: 100%|██████████| 157/157 [00:00&lt;00:00, 160.88it/s, Epoch: 8, Batch: 157,Loss: 0.129,Avg.Loss: 0.126,LR: 4.80E-05]
Training epoch 9: 100%|██████████| 157/157 [00:00&lt;00:00, 167.60it/s, Epoch: 9, Batch: 157,Loss: 0.126,Avg.Loss: 0.124,LR: 1.24E-05]
Training epoch 10: 100%|██████████| 157/157 [00:00&lt;00:00, 162.16it/s, Epoch: 10, Batch: 157,Loss: 0.113,Avg.Loss: 0.122,LR: 5.07E-10]
</pre></div>
</div>
</div>
</div>
<p>Finally, we can make a quick visual sanity check by plotting the estimates agains the true parameters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Quick point estimates can be obtained by simply calling the .estimate() method</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">config</span><span class="p">(</span><span class="n">benchmark</span><span class="o">.</span><span class="n">generative_model</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">estimates</span> <span class="o">=</span> <span class="n">amortizer</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">true_params</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plot_recovery</span><span class="p">(</span>
    <span class="n">estimates</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">true_params</span><span class="p">,</span> <span class="n">uncertainty_agg</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e2fefeb35092c255fe6c875e3acc46e6761c0c520a1cdd384e795c12fc091e58.png" src="../_images/e2fefeb35092c255fe6c875e3acc46e6761c0c520a1cdd384e795c12fc091e58.png" />
</div>
</div>
<p>We can see that the recovery looks sensible, the network seems to have captured at least some information from the data. Try to vary <code class="docutils literal notranslate"><span class="pre">n_obs</span></code> and observe how the correlations change.</p>
</section>
<section id="illustrative-example-from-the-paper">
<h2>Illustrative Example from the Paper<a class="headerlink" href="#illustrative-example-from-the-paper" title="Link to this heading">#</a></h2>
<p>In section 2.2.3 of the paper, a simple one-dimensional example is given as a demonstration and sanity check. Here, we want to replicate the main result, namely that the learned amortized Bayes estimator closely resembles the analytical one. Please refer to the paper for background and formulas.</p>
<p>First, we specify out generative model. The prior is a Pareto distribution with <span class="math notranslate nohighlight">\(\alpha=4\)</span> and <span class="math notranslate nohighlight">\(\beta=1\)</span>. The likelihood is a uniform distribution, with a minimum value of zero and a maximum value which is determined by the parameter <span class="math notranslate nohighlight">\(\theta\)</span>. For efficiency, we create a <em>batched</em> simulator, i.e. we generate a whole batch of data in one function call.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">batch_prior_fun</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Pareto</span><span class="p">(</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">batch_simulator_fun</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">10</span><span class="p">),</span> <span class="n">maxval</span><span class="o">=</span><span class="n">theta</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span>


<span class="n">prior</span> <span class="o">=</span> <span class="n">Prior</span><span class="p">(</span><span class="n">batch_prior_fun</span><span class="o">=</span><span class="n">batch_prior_fun</span><span class="p">)</span>
<span class="n">simulator</span> <span class="o">=</span> <span class="n">Simulator</span><span class="p">(</span><span class="n">batch_simulator_fun</span><span class="o">=</span><span class="n">batch_simulator_fun</span><span class="p">)</span>
<span class="n">generative_model</span> <span class="o">=</span> <span class="n">GenerativeModel</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:root:Performing 2 pilot runs with the anonymous model...
INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 1)
INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 10, 1)
INFO:root:No optional prior non-batchable context provided.
INFO:root:No optional prior batchable context provided.
INFO:root:No optional simulation non-batchable context provided.
INFO:root:No optional simulation batchable context provided.
</pre></div>
</div>
</div>
</div>
<p>Again, we specify a summary network. As the dimensionality is lower (1) this time, a smaller number of summary dimensions should be sufficient. We use <code class="docutils literal notranslate"><span class="pre">norm_ord=1</span></code>, i.e. an absolute-error loss, to obtain the posterior median, as required in this example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_dim</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">summary_net</span> <span class="o">=</span> <span class="n">DeepSet</span><span class="p">(</span><span class="n">summary_dim</span><span class="p">)</span>

<span class="n">inference_net</span> <span class="o">=</span> <span class="n">ConfigurableMLP</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">summary_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

<span class="n">amortizer</span> <span class="o">=</span> <span class="n">AmortizedPointEstimator</span><span class="p">(</span><span class="n">inference_net</span><span class="p">,</span> <span class="n">summary_net</span><span class="o">=</span><span class="n">summary_net</span><span class="p">,</span> <span class="n">norm_ord</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The configurator is similar to the one above, but we skip the <code class="docutils literal notranslate"><span class="pre">.astype</span></code> calls, as the generative model already produces TensorFlow tensors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">config</span><span class="p">(</span><span class="n">forward_dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper function for posterior configuration.&quot;&quot;&quot;</span>

    <span class="n">input_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forward_dict</span><span class="p">[</span><span class="s2">&quot;prior_draws&quot;</span><span class="p">]</span>
    <span class="c1"># we use &quot;summary_conditions&quot; and not &quot;direct_conditions&quot; to pass the data</span>
    <span class="c1"># to the summary network</span>
    <span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;summary_conditions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forward_dict</span><span class="p">[</span><span class="s2">&quot;sim_data&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">input_dict</span>
</pre></div>
</div>
</div>
</div>
<p>This time, we supply the generative model to the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, which enables <em>online</em> training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">trainers</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">amortizer</span><span class="o">=</span><span class="n">amortizer</span><span class="p">,</span> <span class="n">configurator</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">generative_model</span><span class="o">=</span><span class="n">generative_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:root:Performing a consistency check with provided components...
INFO:root:Done.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train_online</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training epoch 1: 100%|██████████| 200/200 [00:03&lt;00:00, 56.05it/s, Epoch: 1, Iter: 200,Loss: 0.103,Avg.Loss: 0.224,LR: 5.00E-04] 
Training epoch 2: 100%|██████████| 200/200 [00:01&lt;00:00, 108.16it/s, Epoch: 2, Iter: 200,Loss: 0.118,Avg.Loss: 0.113,LR: 4.98E-04]
Training epoch 3: 100%|██████████| 200/200 [00:01&lt;00:00, 108.78it/s, Epoch: 3, Iter: 200,Loss: 0.118,Avg.Loss: 0.112,LR: 4.96E-04]
Training epoch 4: 100%|██████████| 200/200 [00:01&lt;00:00, 108.64it/s, Epoch: 4, Iter: 200,Loss: 0.081,Avg.Loss: 0.095,LR: 4.92E-04]
Training epoch 5: 100%|██████████| 200/200 [00:01&lt;00:00, 109.23it/s, Epoch: 5, Iter: 200,Loss: 0.072,Avg.Loss: 0.092,LR: 4.88E-04]
Training epoch 6: 100%|██████████| 200/200 [00:01&lt;00:00, 108.96it/s, Epoch: 6, Iter: 200,Loss: 0.063,Avg.Loss: 0.086,LR: 4.82E-04]
Training epoch 7: 100%|██████████| 200/200 [00:01&lt;00:00, 108.77it/s, Epoch: 7, Iter: 200,Loss: 0.054,Avg.Loss: 0.083,LR: 4.76E-04]
Training epoch 8: 100%|██████████| 200/200 [00:01&lt;00:00, 108.64it/s, Epoch: 8, Iter: 200,Loss: 0.081,Avg.Loss: 0.084,LR: 4.69E-04]
Training epoch 9: 100%|██████████| 200/200 [00:01&lt;00:00, 109.46it/s, Epoch: 9, Iter: 200,Loss: 0.081,Avg.Loss: 0.082,LR: 4.61E-04]
Training epoch 10: 100%|██████████| 200/200 [00:01&lt;00:00, 109.41it/s, Epoch: 10, Iter: 200,Loss: 0.081,Avg.Loss: 0.081,LR: 4.52E-04]
Training epoch 11: 100%|██████████| 200/200 [00:01&lt;00:00, 108.96it/s, Epoch: 11, Iter: 200,Loss: 0.068,Avg.Loss: 0.082,LR: 4.43E-04]
Training epoch 12: 100%|██████████| 200/200 [00:01&lt;00:00, 109.07it/s, Epoch: 12, Iter: 200,Loss: 0.094,Avg.Loss: 0.080,LR: 4.32E-04]
Training epoch 13: 100%|██████████| 200/200 [00:01&lt;00:00, 107.32it/s, Epoch: 13, Iter: 200,Loss: 0.101,Avg.Loss: 0.090,LR: 4.21E-04]
Training epoch 14: 100%|██████████| 200/200 [00:01&lt;00:00, 108.89it/s, Epoch: 14, Iter: 200,Loss: 0.099,Avg.Loss: 0.079,LR: 4.09E-04]
Training epoch 15: 100%|██████████| 200/200 [00:01&lt;00:00, 108.67it/s, Epoch: 15, Iter: 200,Loss: 0.098,Avg.Loss: 0.078,LR: 3.97E-04]
Training epoch 16: 100%|██████████| 200/200 [00:01&lt;00:00, 108.90it/s, Epoch: 16, Iter: 200,Loss: 0.061,Avg.Loss: 0.079,LR: 3.84E-04]
Training epoch 17: 100%|██████████| 200/200 [00:01&lt;00:00, 107.74it/s, Epoch: 17, Iter: 200,Loss: 0.080,Avg.Loss: 0.083,LR: 3.71E-04]
Training epoch 18: 100%|██████████| 200/200 [00:01&lt;00:00, 106.44it/s, Epoch: 18, Iter: 200,Loss: 0.091,Avg.Loss: 0.074,LR: 3.57E-04]
Training epoch 19: 100%|██████████| 200/200 [00:01&lt;00:00, 107.31it/s, Epoch: 19, Iter: 200,Loss: 0.067,Avg.Loss: 0.078,LR: 3.42E-04]
Training epoch 20: 100%|██████████| 200/200 [00:01&lt;00:00, 108.98it/s, Epoch: 20, Iter: 200,Loss: 0.097,Avg.Loss: 0.079,LR: 3.27E-04]
Training epoch 21: 100%|██████████| 200/200 [00:01&lt;00:00, 109.43it/s, Epoch: 21, Iter: 200,Loss: 0.061,Avg.Loss: 0.075,LR: 3.12E-04]
Training epoch 22: 100%|██████████| 200/200 [00:01&lt;00:00, 105.86it/s, Epoch: 22, Iter: 200,Loss: 0.069,Avg.Loss: 0.073,LR: 2.97E-04]
Training epoch 23: 100%|██████████| 200/200 [00:01&lt;00:00, 105.20it/s, Epoch: 23, Iter: 200,Loss: 0.099,Avg.Loss: 0.071,LR: 2.81E-04]
Training epoch 24: 100%|██████████| 200/200 [00:01&lt;00:00, 106.32it/s, Epoch: 24, Iter: 200,Loss: 0.078,Avg.Loss: 0.076,LR: 2.66E-04]
Training epoch 25: 100%|██████████| 200/200 [00:01&lt;00:00, 107.06it/s, Epoch: 25, Iter: 200,Loss: 0.050,Avg.Loss: 0.070,LR: 2.50E-04]
Training epoch 26: 100%|██████████| 200/200 [00:01&lt;00:00, 107.35it/s, Epoch: 26, Iter: 200,Loss: 0.071,Avg.Loss: 0.073,LR: 2.34E-04]
Training epoch 27: 100%|██████████| 200/200 [00:01&lt;00:00, 105.60it/s, Epoch: 27, Iter: 200,Loss: 0.085,Avg.Loss: 0.075,LR: 2.19E-04]
Training epoch 28: 100%|██████████| 200/200 [00:01&lt;00:00, 108.09it/s, Epoch: 28, Iter: 200,Loss: 0.096,Avg.Loss: 0.075,LR: 2.03E-04]
Training epoch 29: 100%|██████████| 200/200 [00:01&lt;00:00, 105.20it/s, Epoch: 29, Iter: 200,Loss: 0.066,Avg.Loss: 0.073,LR: 1.88E-04]
Training epoch 30: 100%|██████████| 200/200 [00:01&lt;00:00, 108.35it/s, Epoch: 30, Iter: 200,Loss: 0.074,Avg.Loss: 0.072,LR: 1.73E-04]
Training epoch 31: 100%|██████████| 200/200 [00:01&lt;00:00, 108.97it/s, Epoch: 31, Iter: 200,Loss: 0.083,Avg.Loss: 0.071,LR: 1.58E-04]
Training epoch 32: 100%|██████████| 200/200 [00:01&lt;00:00, 108.93it/s, Epoch: 32, Iter: 200,Loss: 0.052,Avg.Loss: 0.075,LR: 1.44E-04]
Training epoch 33: 100%|██████████| 200/200 [00:01&lt;00:00, 107.14it/s, Epoch: 33, Iter: 200,Loss: 0.094,Avg.Loss: 0.072,LR: 1.30E-04]
Training epoch 34: 100%|██████████| 200/200 [00:01&lt;00:00, 103.79it/s, Epoch: 34, Iter: 200,Loss: 0.084,Avg.Loss: 0.069,LR: 1.16E-04]
Training epoch 35: 100%|██████████| 200/200 [00:01&lt;00:00, 106.52it/s, Epoch: 35, Iter: 200,Loss: 0.061,Avg.Loss: 0.070,LR: 1.03E-04]
Training epoch 36: 100%|██████████| 200/200 [00:01&lt;00:00, 108.07it/s, Epoch: 36, Iter: 200,Loss: 0.062,Avg.Loss: 0.070,LR: 9.07E-05]
Training epoch 37: 100%|██████████| 200/200 [00:01&lt;00:00, 109.10it/s, Epoch: 37, Iter: 200,Loss: 0.065,Avg.Loss: 0.069,LR: 7.89E-05]
Training epoch 38: 100%|██████████| 200/200 [00:01&lt;00:00, 107.48it/s, Epoch: 38, Iter: 200,Loss: 0.071,Avg.Loss: 0.066,LR: 6.78E-05]
Training epoch 39: 100%|██████████| 200/200 [00:01&lt;00:00, 108.96it/s, Epoch: 39, Iter: 200,Loss: 0.064,Avg.Loss: 0.068,LR: 5.74E-05]
Training epoch 40: 100%|██████████| 200/200 [00:01&lt;00:00, 107.48it/s, Epoch: 40, Iter: 200,Loss: 0.074,Avg.Loss: 0.068,LR: 4.78E-05]
Training epoch 41: 100%|██████████| 200/200 [00:01&lt;00:00, 109.38it/s, Epoch: 41, Iter: 200,Loss: 0.073,Avg.Loss: 0.067,LR: 3.90E-05]
Training epoch 42: 100%|██████████| 200/200 [00:01&lt;00:00, 108.21it/s, Epoch: 42, Iter: 200,Loss: 0.057,Avg.Loss: 0.069,LR: 3.10E-05]
Training epoch 43: 100%|██████████| 200/200 [00:01&lt;00:00, 104.41it/s, Epoch: 43, Iter: 200,Loss: 0.047,Avg.Loss: 0.067,LR: 2.38E-05]
Training epoch 44: 100%|██████████| 200/200 [00:01&lt;00:00, 101.10it/s, Epoch: 44, Iter: 200,Loss: 0.082,Avg.Loss: 0.067,LR: 1.76E-05]
Training epoch 45: 100%|██████████| 200/200 [00:01&lt;00:00, 101.59it/s, Epoch: 45, Iter: 200,Loss: 0.051,Avg.Loss: 0.068,LR: 1.23E-05]
Training epoch 46: 100%|██████████| 200/200 [00:01&lt;00:00, 102.91it/s, Epoch: 46, Iter: 200,Loss: 0.084,Avg.Loss: 0.069,LR: 7.87E-06]
Training epoch 47: 100%|██████████| 200/200 [00:01&lt;00:00, 102.77it/s, Epoch: 47, Iter: 200,Loss: 0.100,Avg.Loss: 0.070,LR: 4.44E-06]
Training epoch 48: 100%|██████████| 200/200 [00:01&lt;00:00, 106.29it/s, Epoch: 48, Iter: 200,Loss: 0.071,Avg.Loss: 0.067,LR: 1.98E-06]
Training epoch 49: 100%|██████████| 200/200 [00:01&lt;00:00, 107.22it/s, Epoch: 49, Iter: 200,Loss: 0.063,Avg.Loss: 0.069,LR: 4.98E-07]
Training epoch 50: 100%|██████████| 200/200 [00:01&lt;00:00, 106.95it/s, Epoch: 50, Iter: 200,Loss: 0.068,Avg.Loss: 0.067,LR: 1.49E-11]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 4min 19s, sys: 18.3 s, total: 4min 37s
Wall time: 1min 35s
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<p>To test the estimator, we generate data with a fixed parameter <span class="math notranslate nohighlight">\(\theta=4/3\)</span>. To keep the code as simple as possible, we just modify the prior of the simulator to only return the desired theta:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Quick point estimates can be obtained by simply calling the .estimate() method</span>
<span class="n">num_test</span> <span class="o">=</span> <span class="mi">30_000</span>
<span class="n">test_param_fun</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">/</span> <span class="mi">3</span>  <span class="c1"># set theta to 4/3 for all simulations</span>
<span class="n">test_model</span> <span class="o">=</span> <span class="n">GenerativeModel</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="n">Prior</span><span class="p">(</span><span class="n">batch_prior_fun</span><span class="o">=</span><span class="n">test_param_fun</span><span class="p">),</span> <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">config</span><span class="p">(</span><span class="n">test_model</span><span class="p">(</span><span class="n">num_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:root:Performing 2 pilot runs with the anonymous model...
INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 1)
INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 10, 1)
INFO:root:No optional prior non-batchable context provided.
INFO:root:No optional prior batchable context provided.
INFO:root:No optional simulation non-batchable context provided.
INFO:root:No optional simulation batchable context provided.
</pre></div>
</div>
</div>
</div>
<p>Using the amortizers <code class="docutils literal notranslate"><span class="pre">estimate</span></code> method, we can obtain the estimate for each data set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">estimates</span> <span class="o">=</span> <span class="n">amortizer</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">test_data</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 4.94 s, sys: 5.1 s, total: 10 s
Wall time: 1.2 s
</pre></div>
</div>
</div>
</div>
<p>For comparison, we calculate the values with the analytic Bayes estimator as well:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bayes_estimator</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">max_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">m</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">max_vals</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>


<span class="n">reference</span> <span class="o">=</span> <span class="n">bayes_estimator</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="s2">&quot;summary_conditions&quot;</span><span class="p">])[:,</span> <span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we compare both the kernel density estimate of the estimators distribution and the correlation between analytical and estimated values:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">estimates</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Neural Bayes estimator&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Bayes estimator&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\hat\theta$&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7c228379d7d9ad4537c889f143b4716bba242ac205598e27d44c41f2fecf5926.png" src="../_images/7c228379d7d9ad4537c889f143b4716bba242ac205598e27d44c41f2fecf5926.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">reference</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">estimates</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Bayes estimate&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Neural Bayes estimate&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9126f83d6ddfb5cf7a1cdedeb7766d680f2db88047cdd80d13b3837da9023efb.png" src="../_images/9126f83d6ddfb5cf7a1cdedeb7766d680f2db88047cdd80d13b3837da9023efb.png" />
</div>
</div>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-benchmark-from-the-bayesflow-benchmark-suite-gaussian-linear">Simple Benchmark from the BayesFlow Benchmark Suite: Gaussian Linear</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#illustrative-example-from-the-paper">Illustrative Example from the Paper</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Author name not set
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023, BayesFlow authors (lead maintainer: Stefan T. Radev).
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>